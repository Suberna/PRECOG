# -*- coding: utf-8 -*-
"""Untitled35.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U7LKe5bHuBHrzTI4_Lbpirg0UDVMbjL_
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# loading the sensor dataset to a pandas DataFrame
sensor_dataset = pd.read_csv('/content/building_collapse_dataset.csv')

sensor_dataset.head()

sensor_dataset.shape

# getting the statistical measures of the data
sensor_dataset.describe()

"""o - no collapse
1- collapse
"""

sensor_dataset['Collapse'].value_counts()

sensor_dataset.groupby('Collapse').mean()

X = sensor_dataset.drop(columns = 'Collapse', axis=1)
Y = sensor_dataset['Collapse']

print(X)

print(Y)

scaler = StandardScaler()

X = sensor_dataset.drop(columns = ['Collapse','Timestamp', 'Serial_Number'], axis=1)
Y = sensor_dataset['Collapse']

scaler.fit(X)

standardized_data = scaler.transform(X)

print(standardized_data)

X = standardized_data
Y = sensor_dataset['Collapse']

print(X)
print(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

classifier = svm.SVC(kernel='linear')

#training the support vector Machine Classifier
classifier.fit(X_train, Y_train)

"""Model Evaluation
Accuracy score
"""

# accuracy score on the training data
X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)

# accuracy score on the test data
X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print('Accuracy score of the test data : ', test_data_accuracy)

import numpy as np

# Assuming you have your input data stored in a tuple named 'input_data'
input_data = (27.48357077, 35.84629258, 0.535778736)

# Convert the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)

# Standardize the input data
std_data = scaler.transform(input_data_reshaped)  # Assuming 'scaler' is your StandardScaler object
print(std_data)

# Predict using the classifier
prediction = classifier.predict(std_data)  # Assuming 'classifier' is your trained machine learning model
print(prediction)

# Interpret the prediction
if prediction[0] == 0:
    print('The building is not likely to collapse.')
else:
    print('The building is likely to collapse.')

